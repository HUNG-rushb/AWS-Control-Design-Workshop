[
{
	"uri": "//localhost:1313/1-introduce/1.1-architecture/",
	"title": "Architecture",
	"tags": [],
	"description": "",
	"content": "Architecture The architecture is a 3-Tier web app based on Amazon EC2 Auto Scaling group using Amazon RDS database instance as persistent application storage.\nBase Services The workshops uses the following services as the base infrastructure:\nAmazon Elastic Cloud Computing (EC2) Amazon Relational Database Service (RDS) Amazon Elastic Load Balancer (ELB) mazon Virtual Private Cloud (VPC) - Internet Gateway (IG) Control Services The workshops leverages the following services to implement our controls:\nAWS Key Management Service (KMS) AWS Identity and Access Management (IAM) AWS Systems Manager (SSM) - Patch Manager AWS Config Amazon CloudWatch Amazon Simple Notification Service (SNS) AWS Secrets Manager "
},
{
	"uri": "//localhost:1313/",
	"title": "AWS Control Design",
	"tags": [],
	"description": "",
	"content": "Welcome to the AWS Control Design workshop In this session, you will experience the process on identifying, designing and implementing security configurations, detective and preventive guardrails to meet your custom control requirements. You will get hands on a pre-built AWS 3 Tier environment with EC2 Instances and RDS. You will use a main customer scenario and 4 customer exercises to identify their profile and specific service user stories to determine their security control needs. For each scenario you will get to choose the right configuration and control monitoring mechanism for each level. The goal of this workshop is to practice the design and implementation of security configurations and guardrails that meets custom needs beyond AWS Best practices.\nAudience: Security Governance, Risk and Compliance Level: 300 - Advanced - Sessions dive deeper into the selected topic. Presenters assume that the audience has some familiarity with the topic, but may or may not have direct experience implementing a similar solution. Duration 120 min Prerequisites: AWS Account, Admin IAM User/Role. Authors:\nPablo Pagani - Security Practice Manager, ProServe LatAm Miguel Segura - Security Assurance Consultant Andrea Di Fabio - Security Assurance Consultant Issa Basza - Security Assurance Consultant Content Introduction Scenarios Support "
},
{
	"uri": "//localhost:1313/2-scenario/2.1-infra_protect/",
	"title": "Infrastructure Protection",
	"tags": [],
	"description": "",
	"content": "Infrastructure Protection Introduction Time to complete: 25 minutes\nLearning Objectives:\nUnderstand how to configure patching for EC2 instances Create a mechanism to ensure that your instances are periodically updated. Implement reporting mechanism for patching compliance Exercise Requirements Scenario Voyager Security team has provided the controls and technical requirements to ensure that EC2 Linux instances are patched with only security updates regularly every Saturday after 10:00 pm automatically. Voyager does not have a current solution and is looking to adopt a cloud native approach that can be quickly implemented. Additionally, the Security team is asking for evidence that a detective mechanism is in place to ensure that this requirement is satisfied. You as a Cloud Architect will need to understand the current architecture and determine, based on the EC2 User Guide and AWS Config Manage Rules or conformance packages which options are available to configure a patching solution that meets customer requirements.\nNIST Requirement\nControl ID Control Description SI-2c Install security-relevant software and firmware updates within [Assignment: organization-defined time period] of the release of the updates. Customer Requirement\nControl ID Control Description Voyager-ctrl-inf-03 Instances must be patched with security updates weekly on Saturdays. AWS resources review and conclusions\nBy reviewing the following available resources, you will come to conclude what needs to be done to meet Voyager’s control requirements. See below the conclusions.\nResource type Resource name Conclusion AWS service user guide Amazon EC2 User guide / Update management in Amazon EC2 You can use AWS Systems Manager Patch Manager to automate the process of installing security-related updates for both the operating system and applications. AWS service user guide AWS Systems Manager User guide / Creating a patching configuration In a patching configuration, you associate a patching configuration with an existing maintenance window, create a new maintenance window for the configuration, or run a one-time manual patching operation on a set of managed nodes. AWS Conformance pack (NIST) AWS operational best practices for NIST 800 53 rev5 (Search for SI-2 ) Enable ec2-managedinstance-patch-compliance-status-check AWS Config rule to check if Amazon EC2 instance patch compliance in AWS Systems Manager is set as required by your organization. Instructions SSM agent has been installed and pre-configured for you. You are going to confirm that the EC2 instances in the environment are reporting to the SSM console. You need to configure SSM patch manager to run periodically during the pre-approved maintenance window. Configure AWS Config rule to report patching compliance.\nOpen the AWS Systems Manager console , in the left navigation pane, choose Patch Manager.\nChoose Configure patching. In the Instances to patch section, choose Select Instances Manually: Select the check box next to the name of each managed node you want to patch.\nIn the Patching schedule section, choose:\nSchedule in a new Maintenance Window and select a Maintenance Window schedule. Use a CRON schedule builder Under Maintenance Window run frequency, change to Every Saturday at 12:00 Under Maintenance duration select 3 Under Maintenance window name write: NISTPatch or as desired Under Patching Operation select Scan and install Finally press configure patching Now that you setup a patching schedule, click on Patch Now, to get current patching status Leave default configuration to only Scan, and press Patch Now Wait a moment for the operation to complete. You should see a Succeeded notification To set up the detection mechanism go to AWS Config, click on Rules, and Add rule Select an AWS Config Managed rule and find the one named: ec2-managedinstance-patch-compliance-status-check. Click Next On the trigger type keep: all changes. Click Next. Review and confirm details. Click Add rule. Success notification should appear on the top. Click on the rule name (ec2-managedinstance-patch-compliance-status-check).\nClick on Actions / Re-evaluate.\nIn the Resources in scop drop-down, select All.\nConfirm the Compliance status is Compliant.\nYou have completed the first exercise. Please proceed to the next.\n"
},
{
	"uri": "//localhost:1313/1-introduce/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "Customer Scenario Voyager is a global data, analytics, and technology company. It plays an essential role in the economy by helping companies in diverse industries make critical decisions with greater confidence. It helps businesses provide a seamless and positive experience during life’s pivotal moments, like applying for a job or mortgage, financing education, or buying a car. Work with over 2.5B+ consumer credit card files and therefore are regulated by multiple entities. This year acquired through merging and acquisitions a company that specializes in preventing fraud risk and loss. This company that has recently merged with them is proprietary of an application named Fraud Risk and Loss application (FRL) that is running in AWS Cloud. Although the FRL app was initially built for minor demand now needs to address corporate control requirements based on NIST 800-53rev5 before releasing into production.\nYou were hired by Voyager as a Cloud Security Architect and your goal is to design and implement the necessary preventive and detective guardrails before it\u0026rsquo;s launched as part of the organization\u0026rsquo;s portfolio.\nYou have the opportunity to learn the process on how to address these issues while leveraging the AWS documentation and security services to design and implement.\n"
},
{
	"uri": "//localhost:1313/3-support/3.1-troubleshoot/",
	"title": "Troubleshooting",
	"tags": [],
	"description": "",
	"content": "Troubleshooting Troubleshoot EC2 instances or ASG launch error. Review instance type and Region combination General EC2 troubleshooting guide Troubleshoot VPC Flow Logs Troubleshooting Amazon CloudWatch Troubleshooting KMS - Key access "
},
{
	"uri": "//localhost:1313/3-support/3.2-cleanup/",
	"title": "Clean Up",
	"tags": [],
	"description": "",
	"content": "Clean Up If you are using this in an instructor led session, with AWS Event Engine you do not need to run the cleanup steps.\nIn order to prevent charges to your account we recommend cleaning up the infrastructure that was created during this workshop. If you plan to keep things running so you can examine the workshop later, remember to do the cleanup when you are done.\nIf you are running this in your own account. You will need to manually delete some resources before you delete the CloudFormation stacks so please do the following steps in order.\nDisable termination protection for the applicable EC2 instances Open to EC2 console Select the instance Click on Actions, Instance settings, change termination protection Untick the Enable checkbox, click Save. Delete the CloudFormation stack Go to the AWS CloudFormation console Select the appropriate stack Select Action Click Delete Stack Go to the AWS Config console Click on Controls Delete the controls that are not needed. "
},
{
	"uri": "//localhost:1313/2-scenario/2.2-data_protect/",
	"title": "Data Protection",
	"tags": [],
	"description": "",
	"content": "Data Protection Introduction Time to complete: 25 minutes\nLearning Objectives:\nLearn how to tag your Amazon Relational Database Service (Amazon RDS) as Restricted. Modify an AWS Key Management Service (KMS) Customer Managed Key (CMK) policy to be more restrictive. Exercise Requirements Scenario Voyager Security team has provided the controls and technical requirements to ensure that databases are tagged according to their data classification requirements and where applicable approved key types with restrictive policies are in use. In this case the FRL application RDS, needs to be classified as restricted (tag key: restricted) and according to the requirements there must be an AWS KMS Customer managed Key (CMK) with some policy restrictions to ensure access follows least privileges. You as a Cloud Architect will need to understand the current architecture and determine, based on the RDS and KMS User Guides how to configure the right tag and an appropriate encryption key policy. Additionally, you will need to find and enable the appropriate AWS Config Manage Rule that should detect if a tag key: restricted is in place.\nNIST Requirement\nControl ID Control Description SC-8(4) Implement cryptographic mechanisms to conceal or randomize communication patterns unless otherwise protected by [Assignment: organization-defined alternative physical controls]. SC-12 Establish and manage cryptographic keys when cryptography is employed within the system in accordance with the following key management requirements: [Assignment: organization-defined requirements for key generation, distribution, storage, access, and destruction]. Customer Requirement\nControl ID Control Description Voyager-ctrl-dp-02 Storage resources including Databases shall be tagged with Data classification key (public, internal or restricted) Voyager-ctrl-dp-04 Cryptographic key access policy to protect restricted data shall be limited to the authorized service and resource. Access to this key shall not be granted to individuals. AWS resources review and conclusions\nBy reviewing the following available resources, you will come to conclude what needs to be done to meet Voyager’s control requirements. See below the conclusions.\nResource type Resource name Conclusion AWS service user guide Amazon RDS user guide / Tagging Amazon RDS resources An Amazon RDS tag is a name-value pair that you define and associate with an Amazon RDS resource. The name is referred to as the key. Supplying a value for the key is optional. You can use tags to assign arbitrary information to an Amazon RDS resource. AWS service user guide Amazon RDS user guide / Encrypting Amazon RDS resources Amazon RDS uses an AWS KMS key to encrypt its resources. For an Amazon RDS encrypted DB instance, all logs, backups, and snapshots are encrypted. AWS service user guide AWS KMS user guide / Permissions for AWS services in key policies AWS KMS key policy must allow the service the minimum permissions that it requires to protect the resource on your behalf. We recommend that you follow the principle of least privilege: give the service only the permissions that it requires. You can do this effectively by learning which permissions the service needs and using AWS global condition keys and AWS KMS condition keys to refine the permissions. Instructions Open the Amazon RDS console\nSelect the Databases section and click on the DB identifier to open instance properties\nSelect Tags tab and click on Add Enter Tag Key: Classification, and Value: Restricted. Click Add Select the Configuration tab, click on the AWS KMS Key ID to navigate into its properties. Click Edit and review the Key policy. You will find that: It allows the KMSAdminRole and root (Administrator Principal) to decrypt data. Typically, Admins should not be allowed this Action. It allows the DevOpsRole (User Principal) to Delete or Revoke the key. Typically, users should not be allowed this Action. Click Edit to update the Key policy: Remove the following Action(s) from the Administrators section (KMSAdminRole) \u0026#34;kms:Encrypt\u0026#34;,\r\u0026#34;kms:Decrypt\u0026#34;,\r\u0026#34;kms:ReEncrypt*\u0026#34;,\r\u0026#34;kms:GenerateDataKey*\u0026#34;, Remove the following Action(s) from the User section (DevOpsRole) \u0026#34;kms:Revoke*\u0026#34;,\r\u0026#34;kms:Disable*\u0026#34;,\r\u0026#34;kms:Delete*\u0026#34;, Once you finish Save changes Go to the AWS Config console to validate if the RDS instance has been tagged with data classification key. Click on Rules, Add rule Select Add AWS Managed rule and search for required-tags. Select it and click Next. Under Resource category, select AWS resources. Under Resource type pick AWS RDS DBInstance. Under Parameters enter the following Key/Value Key: tag1Key\rValue: Classification\r(Replace the value from CostCenter to Classification)\rKey: tag1Value\rValue: Public,Confidential,Restricted Click Next\nReview and click Add rule.\nClick on the new rule name (required-tags)\nClick on Actions, Re-evaluate\nIn the Resources in scope, click the Refresh arrow and validate compliance status. (It can take a moment to update the compliance status)\nOptional) Go back to the resource, change or remove the tagValue and validate if it changes the compliance status. Remember to re-evaluate, wait a moment, and refresh the resources in scope section to see the Compliance change. You have completed exercise two. Please proceed to the next exercise.\n"
},
{
	"uri": "//localhost:1313/1-introduce/1.2-naae/",
	"title": "Not Attending AWS hosted event",
	"tags": [],
	"description": "",
	"content": "Not Attending AWS hosted event If you are attending an AWS hosted event, you can stop reading an continue with next step using the provided accounts.\nDownload (right-click and Save link as\u0026hellip;) CloudFormation template with the base architecture required to create the environment for this workshop.\nUsing your own test account (please don\u0026rsquo;t use production accounts) go to the CloudFormation console\nClick on create stack, With new resources (standard)\nEnter Stack name control-design. Click Next Use default stack options. Click Next Review Details Click the \u0026ldquo;I acknowledge\u0026hellip;\u0026rdquo; checkbox. Click Create stack Wait for all resources to complete creation. If any error appears, refer to the Support/Troubleshooting section. Once you finish this workshop, go to the Support/Cleanup section, to reduce incurred costs.\n"
},
{
	"uri": "//localhost:1313/2-scenario/",
	"title": "Scenario ",
	"tags": [],
	"description": "",
	"content": "Scenario We are requested to implement NIST 800-53r5 controls using the Cloud Adoption Framework (CAF) capabilities :\nInfrastructure Protection Data Protection Security Assurance Identity and Access Management "
},
{
	"uri": "//localhost:1313/1-introduce/1.3-aae/",
	"title": "Attending AWS hosted event",
	"tags": [],
	"description": "",
	"content": "\rIf you are NOT attending an AWS hosted event, you can stop reading an continue with next step using your own test account.\nIf you are attending an AWS hosted event, you will be provided with an AWS account via the AWS Event Engine service. A team hash will be provided to you by event staff.\nIf you are currently logged in to an AWS Account, you should log out or open an incognito window in your browser\nLogging into Event Engine Dashboard Connect to the portal by clicking the button or browsing to https://dashboard.eventengine.run/. The following screen shows up. Enter the provided hash in the text box. The button in the bottom right corner changes to Accept Terms \u0026amp; Login. Click on that button to continue. Choose OTP (Email One-Time Password). Enter your personal or corporate email to receive a one-time password. Enter your personal or corporate email to receive a one-time password. Copy the passcode that was sent to your email, paste in the console and click Sign In. Click on AWS Console. Click on Open AWS Console. Use a single region for the duration of this workshop. Please select US East (N.Virginia) in the top right corner. Once you finish this workshop, go to the Support/Cleanup section, to reduce incurred costs.\n"
},
{
	"uri": "//localhost:1313/3-support/3.3-resources/",
	"title": "Resources",
	"tags": [],
	"description": "",
	"content": "Resources Review the following material:\nAWS Config Conformance Packs : A conformance pack is a collection of AWS Config rules and remediation actions that can be easily deployed as a single entity in an account and a Region or across an organization in AWS Organizations. Security standards and controls in AWS Security Hub : AWS Security Hub consumes, aggregates, and analyzes security findings from various supported AWS and third-party products. Security in AWS CloudFormation : Configure AWS CloudFormation to meet your security and compliance objectives. You also learn how to use other AWS services that help you to monitor and secure your AWS CloudFormation resources. AWS Audit Manager Control library : The control library contains a catalog of standard controls (predefined controls that are provided by AWS) and custom controls (customized controls that you own and define). AWS Systems Manager Compliance : You can use Compliance, a capability of AWS Systems Manager, to scan your fleet of managed nodes for patch compliance and configuration inconsistencies. You can collect and aggregate data from multiple AWS accounts and Regions, and then drill down into specific resources that aren’t compliant. "
},
{
	"uri": "//localhost:1313/2-scenario/2.3-security_assurance/",
	"title": "Security Assurance",
	"tags": [],
	"description": "",
	"content": "Security Assurance Introduction Time to complete: 25 minutes\nLearning Objectives:\nSetup Logging at OS Level using Amazon CloudWatch. Setup notifications concerning relevant OS events. Exercise Requirements Scenario Voyager Security team has provided the technical requirements to ensure that Operating Systems (OS) logs are captured, and alerts are sent to monitoring and response teams for critical events. For example, root access shall be considered a critical event and should trigger an alert to the monitoring team via email. You as a Cloud Architect will need to understand the current architecture and determine, based on the AWS CloudWatch and AWS Config Manage Rules or conformance packages which options are available to configure a logging solution that meets customer requirements.\nNIST Requirement\nControl ID Control Description AC-6(9) Log the execution of privileged functions. AU-2 Event Logging AU-6(1) Audit Record Review, Analysis, and Reporting Customer Requirement\nControl ID Control Description Voyager-ctrl-mon-01 Systems must be appropriately monitored. Logs needs to be captured at the OS level and alerts will need to be triggered and sent to SOC team when root is used. AWS resources review and conclusions\nBy reviewing the following available resources, you will come to conclude what needs to be done to meet Voyager’s control requirements. See below the conclusions.\nResource type Resource name Conclusion AWS service user guide AWS CloudWatch / What is Amazon CloudWatch Logs? CloudWatch Logs enables you to centralize the logs from all of your systems, applications, and AWS services that you use, in a single, highly scalable service. AWS service user guide AWS CloudWatch agent guide / Collecting metrics and logs from Amazon EC2 instances and on-premises servers with the CloudWatch agent The cloud native approach to record OS logs is by installing AWS CloudWatch agent in each instance. AWS service user guide CloudWatch Alarm events and EventBridge CloudWatch sends events to Amazon EventBridge whenever a CloudWatch alarm is created, updated, deleted, or changes alarm state. You can use EventBridge and these events to write rules that take actions, such as notifying you, when an alarm changes state. AWS Conformance pack (NIST) AWS operational best practices for NIST 800 53 rev5 (Search for AC-6(9), AU-2, AU-6(1)) Use Amazon CloudWatch to centrally collect and manage log event activity. Inclusion of AWS CloudTrail data provides details of API call activity within your AWS account. Instructions CloudWatch Logs introduction Logs are an essential tool to gain visibility into what is happening in your instances. Besides Metrics, CloudWatch allows you to collect and search logs.\nBefore we dive into CloudWatch Logs, we need to understand the concepts of log stream and log groups .\nA log stream is a sequence of log events coming from the same source (e.g., EC2 instance).\nA log group is a group of log streams that shares the same retention, monitoring and access control settings. Used for logical grouping of the log streams. If EC2 instances are running the same application, we can group their log streams into one log group.\nCloudWatch Logs analysis Our EC2 instances generates many log files. The Linux operating system has its own log, and our application running on it can also generate their own logs.\nThese logs can be collected by the CloudWatch agent , an agent application that (optionally) runs in your EC2 instances.\nCloudWatch agent is pre-installed and configured to collect the logs in all the EC2 instances for this part of the workshop.\nTo see the logs, open the CloudWatch console In the left navigation pane, under Logs, choose Log groups. There is already one log group named /var/log/secure. Click on it and you should see the log group details and a few log streams under for each instance. Click Actions/Edit retention setting. Select the desired expiration time. (for this exercise choose 12 month). Click Save. Click Actions from the top-right corner and click create metric filter. Define a pattern to search for. You can input session opened for user root and it will look for it in the logs. Click Next. Complete the metric filter details as shown in the image. Click Next Review details and click on Create metric filter. Click on Audit under Metric. An empty graph will appear. CloudWatch will only generate metrics from events generated after the metric was generated. Navigate to the EC2 console, click on instances, select one of the instances and click Connect(top right) . Under Session Manager, click Connect. Once the terminal connection opens. you can run sudo su to escalate to root user. This way you will generate additional events in the log. Click Terminate twice. Go back to CloudWatch console on the left under Metrics, click All Metrics, and under Custom namespaces, click Audit and then Metrics with no dimensions. Check session opened for user root checkbox. A dot with the session we generated will appear in the graph. (It can take up to 5 mins for the information to get displayed) (Optional) To learn more about filter patterns look at the CloudWatch documentation\n(Optional) Once you configure a metric you can configure CloudWatch alarms to receive a notification every time someone logins with root user.\nYou have completed exercise three. Please proceed to the next exercise.\n"
},
{
	"uri": "//localhost:1313/3-support/",
	"title": "Support",
	"tags": [],
	"description": "",
	"content": "Support Troubleshooting Cleanup Resources "
},
{
	"uri": "//localhost:1313/2-scenario/2.4-iam/",
	"title": "Identity and Access Management",
	"tags": [],
	"description": "",
	"content": "Identity and Access Management Introduction Time to complete: 25 minutes\nLearning Objectives:\nConfigure your IAM policies to prevent unauthorized traffic mirroring of your VPC network. Deploy an AWS Config custom rule to detect traffic mirroring on the VPC. Exercise Requirements Scenario Voyager Security team has provided the controls and technical requirements to ensure that their developers follow least privileges when it comes to manage their VPC network components. The developer team is using the IAM Role DevOps which is now permissive enough to allow them to place a traffic mirror listener in the account without the security team knowing. Even if this traffic is internal, it is considered highly restricted. Your goal as a Cloud Architect will be to configure the right IAM permissions to prevent traffic mirror action and a detective mechanism to alert.\nNIST Requirement\nControl ID Control Description AC-4(21) Separate information flows logically or physically using [Assignment: organization-defined mechanisms and/or techniques] to accomplish [Assignment: organization-defined required separations by types of information]. AC-3 Enforce approved authorizations for logical access to information and system resources in accordance with applicable access control policies. Customer Requirement\nControl ID Control Description Voyager-ctrl-net-05 Developers must be restricted to make changes on VPC resources that could expose the network to unauthorized resources. AWS resources review and conclusions\nBy reviewing the following available resources, you will come to conclude what needs to be done to meet Voyager’s control requirements. See below the conclusions.\nResource type Resource name Conclusion AWS service IAM actions Amazon VPC actions You can use AWS Systems Manager Patch Manager to automate the process of installing security-related updates for both the operating system and applications. AWS service user guide AWS Config / Managed rules There isn’t a managed AWS config rule available to detect traffic mirror so we need to build a custom check. AWS Service user guide AWS Config / Creating AWS Config custom Lambda rules You can develop custom rules and add them to AWS Config with AWS Lambda functions. You associate each custom rule with an Lambda function, which contains the logic that evaluates whether your AWS resources comply with the rule. Instructions Open to the IAM Console under the Roles section, search for the DevOps role, and click over the Role Name. (it may have an aleatory suffix) Expand the Policy clicking on the (+) sign. Click the Edit button. Select the JSON tab. Modify the policy to remove the ability to create Traffic Mirror sessions under the NotAction policy element. These two actions: \u0026#34;ec2:CreateTrafficMirrorSession\u0026#34;\r\u0026#34;ec2:CreateTrafficMirrorTarget\u0026#34; Can be simplified into one element using a wildcard like this:\n\u0026#34;ec2:CreateTrafficMirror*\u0026#34; Select Review policy and then save changes. Now that you have reduced the DevOpsRole privileges, it\u0026rsquo;s time to create a mechanism to detect if a traffic mirror is enabled. To do it you are going to create a new custom AWS Config rule. We have prepared a CloudFormation template that validates if TrafficMirror Sessions or Targets are in place. This cloudFormation template creates a Config rule that together with a Lambda function and the necessary permissions detects when a Traffic Mirror is in place. (This is an example of how custom controls can be implemented to suit your needs)\nDownload this CloudFormation template to your disk.\nOpen the AWS CloudFormation console and click create a new stack.\nSelect Template is ready and select Upload a template file. Click on Choose a file. Select the file you just downloaded to your disk. Click Next. Provide the following name to the stack, and click Next. Leave the stack options as is, and click Next. Select the check box to acknowledge and press Create stack. Review the status, click on the refresh button until it has finished successfully. Go to the AWS Config console and under rules option verify that the new config rule was created. To test this rule, go to VPC console\nOn the left under Traffic Mirroring, select Mirror targets.\nOn the top right, click on Create a new Traffic Mirror target. (Keep in mind that initially we have reduced the privileges of the DevOps role but not yours).\nClick on the Target textbox and select any of the EC2 ENI. Click Create. Go back to the AWS Config console select the rule we created, and click Re-evaluate. Wait a moment and refresh. The rule should change from Compliant status to Noncompliant Congratulations! You have completed the last exercise.\n"
},
{
	"uri": "//localhost:1313/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]